# NLP Scraper

Проект для сбора новостей с выбранного источника (Variety) и их обогащения с помощью NLP:

- извлечение организаций (spaCy NER, тип ORG),
- определение темы статьи (topic classifier, `results/topic_classifier.pkl`),
- анализ тональности (NLTK VADER),
- детекция “экологического скандала” через семантическую близость к списку ключевых слов,
- сохранение результата в единый CSV.

## Структура проекта

```text
.
├── data/
│   ├── articles_YYYY-MM-DD.jsonl   # результаты скрейпера
│   ├── topic_train.csv             # обучающие данные для классификатора тем
│   └── topic_test.csv              # тестовые данные для классификатора тем
├── results/
│   ├── training_model.py           # скрипт обучения классификатора тем
│   ├── topic_classifier.pkl        # обученная модель
│   ├── learning_curves.png         # (создаётся, если данных достаточно)
│   └── enhanced_news.csv           # обогащённые новости
├── scraper_news.py                 # скрейпер с variety.com
├── nlp_enriched_news.py            # NLP-движок
├── requirements.txt
└── README.md

 ## Установка окружения

 python -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
python -m spacy download en_core_web_sm
python -m nltk.downloader vader_lexicon
python -m nltk.downloader punkt
python -m nltk.downloader punkt_tab

1. Сбор новостей
python scraper_news.py

Скрипт пройдётся по нескольким разделам Variety и сохранит статьи в data/articles_YYYY-MM-DD.jsonl с полями:

-id
-url
-date
-headline
-body

Сейчас скрипт обходит несколько страниц и может собрать >200 статей за запуск.

2. Обучение классификатора тем

python results/training_model.py

Скрипт:

-читает data/topic_train.csv и data/topic_test.csv;
-обучает TF-IDF + LogisticRegression;
-пытается построить learning curve (если хватит данных);
-сохраняет модель в results/topic_classifier.pkl.
-Если данных мало, скрипт пропустит построение графика и просто сохранит модель.

3. NLP-обогащение новостей

python nlp_enriched_news.py

Скрипт:

-Загружает последние собранные статьи из data/.
-Извлекает ORG через spaCy.
-Подгружает модель тем из results/topic_classifier.pkl.
-Считает тональность через NLTK VADER.
-Считает “scandal_distance”: берёт предложения с организациями и сравнивает их с эмбеддингами экологических ключевых слов -(pollution, deforestation, ...), берёт максимум.
-Сортирует по Scandal_distance и помечает top-10 статей как Top_10=True.
-Сохраняет всё в results/enhanced_news.csv.

Структура CSV:

-uuid
-URL
-date
-headline
-body
-Org (список строк)
-Topics (список строк)
-Sentiment (float, VADER compound)
-Scandal_distance (float)
-Top_10 (bool)
-Объяснение выбора эмбеддингов и метрики
-Для детекции скандалов использована модель sentence-transformers/all-MiniLM-L6-v2, потому что:
-она достаточно лёгкая, чтобы запускать локально;
-даёт sentence-level эмбеддинги;
-поддерживается библиотекой sentence-transformers.

Для сравнения использовано cosine similarity (util.cos_sim), т.к. это стандартная метрика для сравнения нормализованных эмбеддингов. В качестве итоговой метрики по статье берётся максимум similarity между ключевыми словами и предложениями, содержащими упомянутые организации.

Описание модели

Модель классификации тематик обучалась с использованием пайплайна TF–IDF + Logistic Regression на размеченном наборе данных из 125 примеров (5 тематик × 25 текстов в каждой).
Для проверки способности модели к обобщению была построена кривая обучения: точность на валидации увеличивается с ростом объёма данных, в то время как точность на обучающей выборке остаётся постоянной (1.0), что указывает на лёгкое переобучение — типичное для небольших датасетов.

-Алгоритм: Logistic Regression (многоклассовая классификация)
-Векторизация: TfidfVectorizer (1–2-граммы, английские стоп-слова)
-Точность на обучении: 1.00
-Точность на валидации: ~0.70
-Точность на тесте: 1.00
-Файл модели: results/topic_classifier.pkl
-Кривая обучения: results/learning_curves.png

# Эмбеддинги и обнаружение скандалов

Для выявления потенциальных экологических скандалов используется предобученная модель SentenceTransformer all-MiniLM-L6-v2.
Ключевые слова, связанные с экологическими катастрофами (например, pollution, deforestation, oil spill), преобразуются в векторы эмбеддингов и сравниваются с предложениями статей, в которых упоминаются обнаруженные организации, при помощи косинусного сходства.
Меньшее расстояние указывает на большую семантическую близость.
10 статей с наименьшей дистанцией отмечаются как потенциально связанные с экологическими скандалами.

# Мой подход

-Разработал и отладил кастомный веб-скрейпер для портала Variety.com (новости о киноиндустрии).
-Собрал и структурировал более 200 статей с заголовками, ссылками и датами публикации.
-Реализовал полный NLP-конвейер, включающий:
-извлечение сущностей (SpaCy)
-классификацию тем (кастомная модель TF–IDF + Logistic Regression)
-анализ тональности (NLTK VADER)
-обнаружение скандалов (эмбеддинги SentenceTransformers)
-Проверил способность модели к обобщению с помощью кривой обучения.
-Сформировал чистый и обогащённый датасет (results/enhanced_news.csv), включающий все поля, требуемые для аудита проекта.

## Итоговые результаты проекта
| Файл                           | Описание                                                                           |
| ------------------------------ | ---------------------------------------------------------------------------------- |
| `scraper_news.py`              | Скрипт для сбора новостей                                                          |
| `results/training_model.py`    | Обучение классификатора тем и построение кривой обучения                           |
| `results/learning_curves.png`  | Визуализация кривой обучения                                                       |
| `results/topic_classifier.pkl` | Обученная модель классификатора тем                                                |
| `nlp_enriched_news.py`         | Основной NLP-движок                                                                |
| `results/enhanced_news.csv`    | Обогащённый датасет с организациями, темами, тональностью и скандальными метриками |
| `README.md`                    | Документация проекта                                                               |
| `requirements.txt`             | Зависимости Python                                                                 |

